{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim, word2vec\n",
    "\n",
    "Gensim &ndash; это библиотека для тематического моделирования текстов. Один из компонентов в ней &ndash; питоновская обёртка для word2vec (который в оригинале был написан на C++).\n",
    "\n",
    "Если gensim у вас не стоит, то ставим:\n",
    "\n",
    "`pip install gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с моделью\n",
    "\n",
    "Для каких-то своих индивидуальных нужд и экспериментов бывает полезно самому натренировать модель на нужных данных и с нужными параметрами. Но для каких-то общих целей модели уже есть как для русского языка, так и для английского.\n",
    "\n",
    "Модели для русского скачать можно здесь &ndash; http://rusvectores.org/ru/models\n",
    "\n",
    "Скачаем модель для русского языка, созданную на основе НКРЯ. Поскольку модели бывают разных форматов, то для них написаны разные функции загрузки; бывает полезно учитывать это в своем скрипте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'ruscorpora_rusvectores2.bin.gz'\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.KeyedVectors.load(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скажем, нам интересны такие слова (пример для русского языка):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = ['день_S', 'ночь_S', 'человек_S', 'семантика_S', 'студент_S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частеречные тэги нужны, поскольку это специфика скачанной модели &ndash; она была натренирована на словах, аннотированных их частями речи (и лемматизированных).\n",
    "\n",
    "Попросим у модели 10 ближайших соседей для каждого слова и коэффициент косинусной близости для каждого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "день_S\n",
      "[-0.02580778  0.00970898  0.01941961 -0.02332282  0.02017624  0.07275085\n",
      " -0.01444375  0.03316632  0.01242602  0.02833412]\n",
      "неделя_S 0.7165195941925049\n",
      "месяц_S 0.631048858165741\n",
      "вечер_S 0.5828738808631897\n",
      "утро_S 0.5676207542419434\n",
      "час_S 0.5605547428131104\n",
      "минута_S 0.5297019481658936\n",
      "гекатомбеон_S 0.4897990822792053\n",
      "денек_S 0.48224717378616333\n",
      "полчаса_S 0.48217129707336426\n",
      "ночь_S 0.478074848651886\n",
      "\n",
      "\n",
      "ночь_S\n",
      "[-0.00688948  0.00408364  0.06975466 -0.00959525  0.0194835   0.04057068\n",
      " -0.00994112  0.06064967 -0.00522624  0.00520327]\n",
      "вечер_S 0.6946247816085815\n",
      "утро_S 0.57301926612854\n",
      "ноченька_S 0.5582467317581177\n",
      "рассвет_S 0.555358350276947\n",
      "ночка_S 0.5351512432098389\n",
      "полдень_S 0.5334426760673523\n",
      "полночь_S 0.4786943197250366\n",
      "день_S 0.478074848651886\n",
      "сумерки_S 0.4390218257904053\n",
      "фундерфун_S 0.4340825080871582\n",
      "\n",
      "\n",
      "человек_S\n",
      "[ 0.02013756 -0.02670704 -0.02039861 -0.05477146  0.00086402 -0.01636335\n",
      "  0.04240307 -0.00025525 -0.14045683  0.04785006]\n",
      "женщина_S 0.5979775190353394\n",
      "парень_S 0.4991787374019623\n",
      "мужчина_S 0.4767409861087799\n",
      "мужик_S 0.47383996844291687\n",
      "россиянин_S 0.4719043970108032\n",
      "народ_S 0.4654742181301117\n",
      "согражданин_S 0.45378512144088745\n",
      "горожанин_S 0.44368088245391846\n",
      "девушка_S 0.443144828081131\n",
      "иностранец_S 0.43849867582321167\n",
      "\n",
      "\n",
      "семантика_S\n",
      "[-0.03066749  0.0053851   0.1110732   0.0152335   0.00440643  0.00384104\n",
      "  0.00096944 -0.03538784 -0.00079585  0.03220548]\n",
      "семантический_A 0.533458411693573\n",
      "понятие_S 0.5030269622802734\n",
      "сочетаемость_S 0.4817051887512207\n",
      "актант_S 0.47596412897109985\n",
      "хронотоп_S 0.46330296993255615\n",
      "метафора_S 0.46158891916275024\n",
      "мышление_S 0.4610119163990021\n",
      "парадигма_S 0.4579666256904602\n",
      "лексема_S 0.45688074827194214\n",
      "смысловой_A 0.4543077349662781\n",
      "\n",
      "\n",
      "студент_S\n",
      "[ 0.02558023  0.0529849  -0.07036145  0.00279281 -0.09874777 -0.01620521\n",
      " -0.03918766  0.0326411   0.09191283  0.03495219]\n",
      "преподаватель_S 0.6958175897598267\n",
      "аспирант_S 0.6589953303337097\n",
      "выпускник_S 0.6523088812828064\n",
      "студентка_S 0.6321653127670288\n",
      "профессор_S 0.6080018281936646\n",
      "курсистка_S 0.5818493366241455\n",
      "юрфак_S 0.5806691646575928\n",
      "первокурсник_S 0.5805511474609375\n",
      "семинарист_S 0.5773230791091919\n",
      "гимназист_S 0.5747809410095215\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    # есть ли слово в модели? Может быть, и нет\n",
    "    if word in model:\n",
    "        print(word)\n",
    "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
    "        print(model[word][:10])\n",
    "        # выдаем 10 ближайших соседей слова:\n",
    "        for i in model.most_similar(positive=[word], topn=10):\n",
    "            # слово + коэффициент косинусной близости\n",
    "            print(i[0], i[1])\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Увы!\n",
    "        print(word + ' is not present in the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим косинусную близость пары слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.238956092849\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('человек_S', 'обезьяна_S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найди лишнее!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "картофель_S\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('яблоко_S груша_S виноград_S банан_S картофель_S'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реши пропорцию!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "плов_S\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['пицца_S', 'россия_S'], negative=['италия_S'])[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Туториал основан на https://github.com/elmiram/2016learnpython/blob/master/word2vec.ipynb.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "В качестве домашнего задания надо будет написать чатбота, который превращает все слова в сообщении в ближайшие синонимы.\n",
    "\n",
    "Для этого нам понадобится сначала лемматизировать и разметить по частям речи слова при помощи пакета `pymystem3`.\n",
    "\n",
    "Как и всё, что мы устанавливали до этого, `pymystem3` нужно установить либо через PyCharm, либо при помощи `pip install pymystem3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem() # инициализируем анализатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мама', ', ', 'мыть', ' ', 'красивый', '    \"', 'рама', '\"', '!', '\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.lemmatize('Мама, МЫЛА красивую    \"раму\"!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, Mystem сам умеет разбивать текст на токены и выделять отдельные слова.\n",
    "\n",
    "Анализ текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'gr': 'S,жен,од=им,ед', 'lex': 'мама'}], 'text': 'Мама'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'gr': 'V,несов,пе=прош,ед,изъяв,жен', 'lex': 'мыть'}],\n",
       "  'text': 'МЫЛА'},\n",
       " {'text': '    '},\n",
       " {'analysis': [{'gr': 'A=вин,ед,полн,жен', 'lex': 'красивый'}],\n",
       "  'text': 'красивую'},\n",
       " {'text': ' \"'},\n",
       " {'analysis': [{'gr': 'S,жен,неод=вин,ед', 'lex': 'рама'}], 'text': 'раму'},\n",
       " {'text': '\"'},\n",
       " {'text': '!'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.analyze('Мама, МЫЛА    красивую \"раму\"!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы можно было применять к нашему тексту модель, нужно из массива, который получается при анализе, извлечь лексему ('lex') и частеречный тег ('gr', без дополнительных характеристик типа падежа, рода, числа и так далее), и записать в формате *[мама_S, мыть_V, красивый_A, рама_S]*.\n",
    "\n",
    "Тогда чатбот должен будет выдать примерно следующее:\n",
    "\n",
    "'папа_S помыть_V симпатичный_A створка_S'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
